{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: A Jupyter Notebook magic for talking to ChatGPT.\n",
    "output-file: index.html\n",
    "title: ask_ai\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple library for talking to ChatGPT from within Jupyter Notebook.\n",
    "\n",
    "**Motivation**: _Don't fear ChatGPT taking your job. Fear a person using ChatGPT taking your job._\n",
    "\n",
    "Of course, this is a sensationalized statement. But it very succinctly gets at something deep and important -- [using LLMs in your work can unlock massive productivity gains](https://twitter.com/emollick/status/1631397931604488194?s=20). I do not know of a better way for me to start using these tools than to bring them closer to where I work, which is Jupyter Notebooks.\n",
    "\n",
    "Also, I really hate the \"typewriter effect\" where you are fed a few words at a time through the ChatGPT UI. I'd much rather have the full reply I can scan in a couple of seconds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. `pip install git+https://github.com/radekosmulski/ask_ai.git`\n",
    "2. Set the environment variable `OPENAI_API_KEY` to your OpenAI API key.\n",
    "3. Load the magics in your jupyter notebook: `%load_ext ask_ai.magics`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `%%ai_ask` to start a new conversation, and `%%ai_continue` to continue an existing conversation.\n",
    "\n",
    "`%%ai_ask` starts a conversation with new (blank) context.\n",
    "\n",
    "As long as you using `%%ai_continue` all (or the most recent) previous messages will be forwarded as context. This can be helpful if your question is related to what you have been discussing so far. In other cases, it is faster and cheaper to use `%%ai_ask` as fewer tokens are used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
