{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "{}\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a50cb09c-8ac6-458e-9fff-1cba9a0ca45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "import openai\n",
    "from IPython.display import HTML, display\n",
    "from ipywidgets import widgets\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c97be6ae-40ab-4bfa-9bcf-e62da6972a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:04<00:00,  1.56s/it]\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "loader = DirectoryLoader(\"/home/jinzy/work/automation/ask_gpt/testdocs\", glob=\"**/*.pdf\", show_progress=True, use_multithreading=True)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size = 400,\n",
    "    chunk_overlap  = 30,\n",
    "    length_function = len,\n",
    ")\n",
    "txt_docs = loader.load_and_split(text_splitter=text_splitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efec7d9c-c167-4961-bc21-d82fa1272421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "from langchain.llms import GPT4All\n",
    "from langchain import HuggingFaceHub, LLMChain\n",
    "\n",
    "# initialize Hub LLM\n",
    "# llm = HuggingFaceHub(repo_id='THUDM/chatglm-6b', model_kwargs={\"trust_remote_code\": True})\n",
    "# llm = HuggingFaceHub(repo_id=\"google/flan-t5-xl\", model_kwargs={\"temperature\":1e-10})\n",
    "# llm = ChatGLMService()\n",
    "# llm.load_model()\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "# embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\", \n",
    "#                                            model_kwargs={\"device\": \"cuda\"})\n",
    "txt_docsearch = Chroma.from_documents(txt_docs, embeddings)\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.5, max_tokens=2048)\n",
    "# llm = GPT4All(model=\"/home/jinzy/Downloads/ggml-gpt4all-j-v1.3-groovy.bin\", n_ctx=512, n_threads=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2322d6e-9d18-4b67-9a24-555ae2437215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import (\n",
    "  ChatPromptTemplate,\n",
    "  SystemMessagePromptTemplate,\n",
    "  HumanMessagePromptTemplate\n",
    ")\n",
    "from langchain.memory import ConversationBufferMemory, ConversationSummaryBufferMemory\n",
    "\n",
    "\n",
    "rewritte_template = \"\"\"根据聊天记录和问题，把问题重写为一个独立的、完整的问题。\n",
    "聊天记录:\n",
    "{chat_history}\n",
    "问题: {question}\n",
    "独立问题:\"\"\"\n",
    "\n",
    "# 初始化 prompt 对象\n",
    "prompt = ChatPromptTemplate.from_template(rewritte_template)\n",
    "# 初始化问答链\n",
    "question_generator = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "refine_template = \"\"\"请检查下述检索结果是否可以用于更新回复内容。\n",
    "检索结果:\n",
    "{context_str}\n",
    "\n",
    "如果这个检索结果包含了有用的信息，请根据它和原始回复内容重新生成更好的回复。如果没有帮助，就返回原始回复内容。\n",
    "新的回复：\"\"\"\n",
    "# (\n",
    "#     \"We have the opportunity to refine the existing answer\"\n",
    "#     \"(only if needed) with some more context below.\\n\"\n",
    "#     \"------------\\n\"\n",
    "#     \"{context_str}\\n\"\n",
    "#     \"------------\\n\"\n",
    "#     \"Given the new context, refine the original answer to better \"\n",
    "#     \"answer the question. \"\n",
    "#     \"If the context isn't useful, return the original answer.\"\n",
    "# )\n",
    "refine_prompt = ChatPromptTemplate.from_template(refine_template)\n",
    "doc_chain = load_qa_chain(llm, chain_type=\"refine\", refine_prompt =refine_prompt)\n",
    "\n",
    "summary_template = \"\"\"根据聊天内容增量式生成摘要，在原始摘要上附加新的摘要。\n",
    "EXAMPLE\n",
    "当前摘要: \n",
    "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\n",
    "\n",
    "新的聊天内容:\n",
    "Human: Why do you think artificial intelligence is a force for good?\n",
    "AI: Because artificial intelligence will help humans reach their full potential.\n",
    "\n",
    "新的摘要:\n",
    "The human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\n",
    "END OF EXAMPLE\n",
    "\n",
    "当前摘要:\n",
    "{summary}\n",
    "\n",
    "新的聊天内容:\n",
    "{new_lines}\n",
    "\n",
    "新的摘要:\n",
    "\"\"\"\n",
    "\n",
    "summary_prompt = PromptTemplate(input_variables=[\"summary\", \"new_lines\"], template=summary_template)\n",
    "\n",
    "# memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, prompt = summary_prompt,\n",
    "        max_token_limit=1000, memory_key=\"chat_history\", return_messages=True)\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=txt_docsearch.as_retriever(),\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    "    memory=memory\n",
    ")\n",
    "# chain = ConversationalRetrievalChain.from_llm(llm=llm, retriever=txt_docsearch.as_retriever(), \n",
    "#                                               chain_type='refine', memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a53bf8b-8559-4f77-8301-09b8190c7f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '请用中文解释一下RPM产品中的任务挖掘功能', 'chat_history': [HumanMessage(content='请用中文解释一下RPM产品中的任务挖掘功能', additional_kwargs={}, example=False), AIMessage(content='iS-RPM是一种数据驱动的智能流程自动化解决方案，可以帮助企业在RPA实现过程中自动、智能地发现值得自动化的业务流程，并通过与RPA的无缝对接实现整个RPA规模化闭环。该解决方案具有成熟的跨平台跨系统数据采集能力，支持跨业务如ERP、OA等系统，同时也支持windows桌面、web平台、虚拟机和云桌面的数据采集。使用iS-RPM收集流程和任务级别的数据，可以代替繁琐的人工业务梳理过程，并提供洞察力，帮助企业管理者快速发现业务瓶颈，并根据不同的标准推荐高价值的自动化机会。', additional_kwargs={}, example=False)], 'answer': 'iS-RPM是一种数据驱动的智能流程自动化解决方案，可以帮助企业在RPA实现过程中自动、智能地发现值得自动化的业务流程，并通过与RPA的无缝对接实现整个RPA规模化闭环。该解决方案具有成熟的跨平台跨系统数据采集能力，支持跨业务如ERP、OA等系统，同时也支持windows桌面、web平台、虚拟机和云桌面的数据采集。使用iS-RPM收集流程和任务级别的数据，可以代替繁琐的人工业务梳理过程，并提供洞察力，帮助企业管理者快速发现业务瓶颈，并根据不同的标准推荐高价值的自动化机会。'}\n"
     ]
    }
   ],
   "source": [
    "query = \"请用中文解释一下RPM产品中的任务挖掘功能\"\n",
    "result = chain({\"question\": query})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6df3305-135f-467e-a673-96190ca5eca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "如果您足够了解流程业务，可以针对指定步骤添加过滤并判断它们是否真的有必要重复执行，深入研究数据并验证它们。此外，iS-RPM 还支持对比分析两个不同维度的流程性能，通过选择特定的数据属性值，一次性对比查看流程中的两组路径之间的差异，以确定最佳实践并在不同地区、业务部门和团队之间共享它们。一旦您确定了业务流程的最佳实践，即可逐步开展业务流程的相应改进措施。通过案例详情查看所有案例的步骤细节，可以清晰地了解流程之间的距离，知道案例何时开始超过流程的平均执行时长。\n"
     ]
    }
   ],
   "source": [
    "query = \"请给出一个RPM产品的实际案例\"\n",
    "#result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "result = chain({\"question\": query})\n",
    "#print(result)\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e59c0449-a976-4ab7-9b0a-a6e41757a833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iS-RPM 是一款流程挖掘技术，可以通过摄取系统日志或事件日志来获取业务过程，并重建流程中发生的事情。分析师可以将系统中的事件日志导出为 .csv 文件并上传到流程挖掘平台中，通过数据建模和流程挖掘算法构建出全量的业务流程图，实现企业级流程监控。\n",
      "\n",
      "在长期的运营过程中，企业的标准流程可能无法完全适应员工和客户的工作方式，流程在日常的运行过程中也会有变化。iS-RPM 可以通过对业务数据的识别分析出业务的不同执行方式，将每个案例在整个周期中所采取的每一步叠加到数据模型中，还原出100%客观的流程视图，真实直观的展示员工每一次业务执行轨迹。\n"
     ]
    }
   ],
   "source": [
    "query = \"请介绍一个RPM产品的实际案例\"\n",
    "#result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "result = chain({\"question\": query})\n",
    "\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08990737-6e20-4d05-9c6f-17d181b19b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '请介绍一个RPM产品的实际案例',\n",
       " 'chat_history': [HumanMessage(content='请用中文解释一下RPM产品中的任务挖掘功能', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='iS-RPM是一种数据驱动的智能流程自动化解决方案，可以帮助企业在RPA实现过程中自动、智能地发现值得自动化的业务流程，并通过与RPA的无缝对接实现整个RPA规模化闭环。该解决方案具有成熟的跨平台跨系统数据采集能力，支持跨业务如ERP、OA等系统，同时也支持windows桌面、web平台、虚拟机和云桌面的数据采集。使用iS-RPM收集流程和任务级别的数据，可以代替繁琐的人工业务梳理过程，并提供洞察力，帮助企业管理者快速发现业务瓶颈，并根据不同的标准推荐高价值的自动化机会。', additional_kwargs={}, example=False),\n",
       "  HumanMessage(content='请给出一个RPM产品的实际案例', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='如果您足够了解流程业务，可以针对指定步骤添加过滤并判断它们是否真的有必要重复执行，深入研究数据并验证它们。此外，iS-RPM 还支持对比分析两个不同维度的流程性能，通过选择特定的数据属性值，一次性对比查看流程中的两组路径之间的差异，以确定最佳实践并在不同地区、业务部门和团队之间共享它们。一旦您确定了业务流程的最佳实践，即可逐步开展业务流程的相应改进措施。通过案例详情查看所有案例的步骤细节，可以清晰地了解流程之间的距离，知道案例何时开始超过流程的平均执行时长。', additional_kwargs={}, example=False),\n",
       "  HumanMessage(content='请介绍一个RPM产品的实际案例', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='iS-RPM 是一款流程挖掘技术，可以通过摄取系统日志或事件日志来获取业务过程，并重建流程中发生的事情。分析师可以将系统中的事件日志导出为 .csv 文件并上传到流程挖掘平台中，通过数据建模和流程挖掘算法构建出全量的业务流程图，实现企业级流程监控。\\n\\n在长期的运营过程中，企业的标准流程可能无法完全适应员工和客户的工作方式，流程在日常的运行过程中也会有变化。iS-RPM 可以通过对业务数据的识别分析出业务的不同执行方式，将每个案例在整个周期中所采取的每一步叠加到数据模型中，还原出100%客观的流程视图，真实直观的展示员工每一次业务执行轨迹。', additional_kwargs={}, example=False)],\n",
       " 'answer': 'iS-RPM 是一款流程挖掘技术，可以通过摄取系统日志或事件日志来获取业务过程，并重建流程中发生的事情。分析师可以将系统中的事件日志导出为 .csv 文件并上传到流程挖掘平台中，通过数据建模和流程挖掘算法构建出全量的业务流程图，实现企业级流程监控。\\n\\n在长期的运营过程中，企业的标准流程可能无法完全适应员工和客户的工作方式，流程在日常的运行过程中也会有变化。iS-RPM 可以通过对业务数据的识别分析出业务的不同执行方式，将每个案例在整个周期中所采取的每一步叠加到数据模型中，还原出100%客观的流程视图，真实直观的展示员工每一次业务执行轨迹。'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c7be78c-252d-4c02-86d0-55ac3b30f270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iS-RPM是一个按时间顺序排列的事件序列，显示了案例从流程开始到结束所采取的所有不同路径。每个唯一路径称为一个变体，不遵循标准或公认路径的变体称为偏差。通过多维度的分析，我们可以了解每个环节的时长，定位流程的堵点，从而找到流程优化的切入点。艺赛旗 iS-RPM 的流程发现仪表板支持逐级钻取，通过使用不同的过滤条件（如：步骤筛选、属性筛选等）多维度的流程分析，能够快速了解并定位流程效率低下的根本原因，并量化它们对业务关键性 KPI 指标的影响。在了解流程全貌后，我们可以解决一些业务执行过程中的困惑，例如瓶颈在哪里，订单为什么迟迟未支付等问题。\n"
     ]
    }
   ],
   "source": [
    "query = \"请介绍一个RPM产品的实际案例\"\n",
    "#result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "result = chain({\"question\": query + ' 请用中文回答。'})\n",
    "\n",
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce281092-800b-4fc1-94b9-1c742d195d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': '请介绍一个RPM产品的实际案例 请用中文回答。',\n",
       " 'chat_history': [HumanMessage(content='请给出一个RPM产品的实际案例', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='如果您足够了解流程业务，可以针对指定步骤添加过滤并判断它们是否真的有必要重复执行，深入研究数据并验证它们。此外，iS-RPM 还支持对比分析两个不同维度的流程性能，通过选择特定的数据属性值，一次性对比查看流程中的两组路径之间的差异，以确定最佳实践并在不同地区、业务部门和团队之间共享它们。一旦您确定了业务流程的最佳实践，即可逐步开展业务流程的相应改进措施。通过案例详情查看所有案例的步骤细节，可以清晰地了解流程之间的距离，知道案例何时开始超过流程的平均执行时长。', additional_kwargs={}, example=False),\n",
       "  HumanMessage(content='请介绍一个RPM产品的实际案例', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='iS-RPM 是一款流程挖掘技术，可以通过摄取系统日志或事件日志来获取业务过程，并重建流程中发生的事情。分析师可以将系统中的事件日志导出为 .csv 文件并上传到流程挖掘平台中，通过数据建模和流程挖掘算法构建出全量的业务流程图，实现企业级流程监控。\\n\\n在长期的运营过程中，企业的标准流程可能无法完全适应员工和客户的工作方式，流程在日常的运行过程中也会有变化。iS-RPM 可以通过对业务数据的识别分析出业务的不同执行方式，将每个案例在整个周期中所采取的每一步叠加到数据模型中，还原出100%客观的流程视图，真实直观的展示员工每一次业务执行轨迹。', additional_kwargs={}, example=False),\n",
       "  HumanMessage(content='请介绍一个RPM产品的实际案例 请用中文回答。', additional_kwargs={}, example=False),\n",
       "  AIMessage(content='iS-RPM是一个按时间顺序排列的事件序列，显示了案例从流程开始到结束所采取的所有不同路径。每个唯一路径称为一个变体，不遵循标准或公认路径的变体称为偏差。通过多维度的分析，我们可以了解每个环节的时长，定位流程的堵点，从而找到流程优化的切入点。艺赛旗 iS-RPM 的流程发现仪表板支持逐级钻取，通过使用不同的过滤条件（如：步骤筛选、属性筛选等）多维度的流程分析，能够快速了解并定位流程效率低下的根本原因，并量化它们对业务关键性 KPI 指标的影响。在了解流程全貌后，我们可以解决一些业务执行过程中的困惑，例如瓶颈在哪里，订单为什么迟迟未支付等问题。', additional_kwargs={}, example=False)],\n",
       " 'answer': 'iS-RPM是一个按时间顺序排列的事件序列，显示了案例从流程开始到结束所采取的所有不同路径。每个唯一路径称为一个变体，不遵循标准或公认路径的变体称为偏差。通过多维度的分析，我们可以了解每个环节的时长，定位流程的堵点，从而找到流程优化的切入点。艺赛旗 iS-RPM 的流程发现仪表板支持逐级钻取，通过使用不同的过滤条件（如：步骤筛选、属性筛选等）多维度的流程分析，能够快速了解并定位流程效率低下的根本原因，并量化它们对业务关键性 KPI 指标的影响。在了解流程全貌后，我们可以解决一些业务执行过程中的困惑，例如瓶颈在哪里，订单为什么迟迟未支付等问题。'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75d87a49-ec8a-4c43-933a-3ed3a9458b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConversationSummaryBufferMemory(human_prefix='Human', ai_prefix='AI', llm=ChatOpenAI(verbose=False, callbacks=None, callback_manager=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.5, model_kwargs={}, openai_api_key=None, openai_api_base=None, openai_organization=None, request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=2048), prompt=PromptTemplate(input_variables=['summary', 'new_lines'], output_parser=None, partial_variables={}, template='根据聊天内容增量式生成摘要，在原始摘要上附加新的摘要。\\nEXAMPLE\\n当前摘要: \\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good.\\n\\n新的聊天内容:\\nHuman: Why do you think artificial intelligence is a force for good?\\nAI: Because artificial intelligence will help humans reach their full potential.\\n\\n新的摘要:\\nThe human asks what the AI thinks of artificial intelligence. The AI thinks artificial intelligence is a force for good because it will help humans reach their full potential.\\nEND OF EXAMPLE\\n\\n当前摘要:\\n{summary}\\n\\n新的聊天内容:\\n{new_lines}\\n\\n新的摘要:\\n', template_format='f-string', validate_template=True), summary_message_cls=<class 'langchain.schema.SystemMessage'>, chat_memory=ChatMessageHistory(messages=[HumanMessage(content='请给出一个RPM产品的实际案例', additional_kwargs={}, example=False), AIMessage(content='如果您足够了解流程业务，可以针对指定步骤添加过滤并判断它们是否真的有必要重复执行，深入研究数据并验证它们。此外，iS-RPM 还支持对比分析两个不同维度的流程性能，通过选择特定的数据属性值，一次性对比查看流程中的两组路径之间的差异，以确定最佳实践并在不同地区、业务部门和团队之间共享它们。一旦您确定了业务流程的最佳实践，即可逐步开展业务流程的相应改进措施。通过案例详情查看所有案例的步骤细节，可以清晰地了解流程之间的距离，知道案例何时开始超过流程的平均执行时长。', additional_kwargs={}, example=False), HumanMessage(content='请介绍一个RPM产品的实际案例', additional_kwargs={}, example=False), AIMessage(content='iS-RPM 是一款流程挖掘技术，可以通过摄取系统日志或事件日志来获取业务过程，并重建流程中发生的事情。分析师可以将系统中的事件日志导出为 .csv 文件并上传到流程挖掘平台中，通过数据建模和流程挖掘算法构建出全量的业务流程图，实现企业级流程监控。\\n\\n在长期的运营过程中，企业的标准流程可能无法完全适应员工和客户的工作方式，流程在日常的运行过程中也会有变化。iS-RPM 可以通过对业务数据的识别分析出业务的不同执行方式，将每个案例在整个周期中所采取的每一步叠加到数据模型中，还原出100%客观的流程视图，真实直观的展示员工每一次业务执行轨迹。', additional_kwargs={}, example=False), HumanMessage(content='请介绍一个RPM产品的实际案例 请用中文回答。', additional_kwargs={}, example=False), AIMessage(content='iS-RPM是一个按时间顺序排列的事件序列，显示了案例从流程开始到结束所采取的所有不同路径。每个唯一路径称为一个变体，不遵循标准或公认路径的变体称为偏差。通过多维度的分析，我们可以了解每个环节的时长，定位流程的堵点，从而找到流程优化的切入点。艺赛旗 iS-RPM 的流程发现仪表板支持逐级钻取，通过使用不同的过滤条件（如：步骤筛选、属性筛选等）多维度的流程分析，能够快速了解并定位流程效率低下的根本原因，并量化它们对业务关键性 KPI 指标的影响。在了解流程全貌后，我们可以解决一些业务执行过程中的困惑，例如瓶颈在哪里，订单为什么迟迟未支付等问题。', additional_kwargs={}, example=False)]), output_key=None, input_key=None, return_messages=True, max_token_limit=1000, moving_summary_buffer='iS-RPM是一种数据驱动的智能流程自动化解决方案，可以帮助企业在RPA实现过程中自动、智能地发现值得自动化的业务流程，并通过与RPA的无缝对接实现整个RPA规模化闭环。使用iS-RPM收集流程和任务级别的数据，可以代替繁琐的人工业务梳理过程，并提供洞察力，帮助企业管理者快速发现业务瓶颈，并根据不同的标准推荐高价值的自动化机会。', memory_key='chat_history')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afd39d9-f77c-488a-9ef5-ad908a250f4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f38d1f8-366c-42aa-a8a8-db6bd59d4af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from langchain.llms.base import LLM\n",
    "from langchain.llms.utils import enforce_stop_tokens\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "\n",
    "class ChatGLMService(LLM):\n",
    "    max_token: int = 10000\n",
    "    temperature: float = 0.1\n",
    "    top_p = 0.9\n",
    "    history = []\n",
    "    tokenizer: object = None\n",
    "    model: object = None\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"ChatGLM\"\n",
    "\n",
    "    def _call(self,\n",
    "              prompt: str,\n",
    "              stop: Optional[List[str]] = None) -> str:\n",
    "        response, _ = self.model.chat(\n",
    "            self.tokenizer,\n",
    "            prompt,\n",
    "            history=self.history,\n",
    "            max_length=self.max_token,\n",
    "            temperature=self.temperature,\n",
    "        )\n",
    "        if stop is not None:\n",
    "            response = enforce_stop_tokens(response, stop)\n",
    "        self.history = self.history + [[None, response]]\n",
    "        return response\n",
    "\n",
    "    def load_model(self, model_name_or_path: str = \"THUDM/chatglm-6b\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_name_or_path,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        print('加载chatglm-6b', model_name_or_path)\n",
    "        # 这里使用的是 量化后的模型int4\n",
    "        self.model = AutoModel.from_pretrained(model_name_or_path, trust_remote_code=True).float().half().cuda()\n",
    "        #.half().quantize(4).cuda()\n",
    "        #.half().cuda()\n",
    "        self.model=self.model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
