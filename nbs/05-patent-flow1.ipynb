{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efddb790-e7a9-4f0a-b1b5-38d0bb187ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "import openai\n",
    "from IPython.display import HTML, display\n",
    "from ipywidgets import widgets\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c38abb79-6416-4da4-8f61-1c428cdb0386",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! engine is not default parameter.\n",
      "                    engine was transferred to model_kwargs.\n",
      "                    Please confirm that engine is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azure https://test0406.openai.azure.com/ 2023-03-15-preview\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.memory import ConversationBufferMemory, ConversationSummaryBufferMemory\n",
    "\n",
    "openai.api_type = os.getenv(\"OPENAI_API_TYPE\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_base = os.getenv(\"OPENAI_API_BASE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "print(openai.api_type, openai.api_base, openai.api_version)\n",
    "\n",
    "llm = ChatOpenAI(engine='test0406', model_name=\"gpt-3.5-turbo\", temperature=0.5, max_tokens=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59d31d73-911c-4582-93d5-5c6346ee1d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = '''为了还原用户UI操作流程，需要识别哪些UI操作是相同的，哪些是不同的。比如，提交报销单，两个人填写的报销单可能只有姓名、部门、时间这些内容是相似的，\n",
    "其他的比如出差事由、时间范围等等相差非常大，在页面上看起来也很不一样。但是，它们同属于一个业务操作，应该判断相同操作，即使对应的窗口/应用从视觉上和内容上来看相差非常大。\n",
    "仅用图片相似性无法解决这个问题，因为文字内容变化难以检测；仅用文字比较也不行，因为内容相差很大的UI操作可能属于同一个业务操作。\n",
    "'''\n",
    "\n",
    "solution = '''使用CV算法识别窗口/应用的区域，同一个窗口的区域分布应该是完全一样的。另外，再提取一两个关键标签，代表当前操作的内容。只要窗口区域相似，\n",
    "关键标签相同，就可以判断两个UI操作属于同一个业务操作。识别窗口区域的方法是canny，通过边框识别窗口的主要布局，同一个应用内只有有限的窗口，每个窗口的布局是很少变化的。\n",
    "提交关键标签，是指使用OCR识别窗口中的所有文字，然后提取关键位置的文字，比如窗口标题栏中的文字。两者结合就可以较有效地区分不同窗口，进而判断窗口的相似性。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e546061-fe73-4cb8-846a-593b644db820",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_background = '''你是一个专业的流程挖掘和任务挖掘方面的专利代理，负责专利发明点设计和专利文档起草。请根据以下要解决的问题及解决方案，起草专利的背景介绍部分。\n",
    "专利的背景介绍要包含所解决问题所在的技术领域介绍，问题的简单介绍，以及这个问题所产生的不良影响。\n",
    "要解决的问题: {question}\n",
    "提供的解决方案: {solution}\n",
    "请生成这个专利发明点的背景介绍：'''\n",
    "\n",
    "prompt_background = PromptTemplate(input_variables=['question', 'solution'], template=template_background)\n",
    "background_chain = LLMChain(llm=llm, prompt=prompt_background, output_key='background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0500bf7d-074e-48ae-8f23-c3673c742a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_claims = '''你是一个专业的流程挖掘和任务挖掘方面的专利代理，负责专利发明点设计和专利文档起草。请根据以下要解决的问题及解决方案，起草专利的权利要求部分。\n",
    "在设计专利的权利要求时要一步步来，先判断解决方案的创新性和价值所在，然后再根据创新点来设计对应的权利要求。针对要解决的问题，先将解决方案重新描述为多个步骤，再判断每一个步骤\n",
    "是否有必要存在，若是没有必要，则可以删除；对于必要存在的步骤，再考虑它是否具备创新性。若是不具备，则更新对应的步骤。只要其中一个步骤具备创新性即可。\n",
    "\n",
    "要解决的问题: {question}\n",
    "提供的解决方案: {solution}\n",
    "请生成这个专利发明点的权利要求：'''\n",
    "\n",
    "prompt_claims = PromptTemplate(input_variables=['question', 'solution'], template=template_claims)\n",
    "claims_chain = LLMChain(llm=llm, prompt=prompt_claims, output_key='claims')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ad57207-2cd9-4142-a2b5-6be4c55f37ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_explanation = '''你是一个专业的流程挖掘和任务挖掘方面的专利代理，负责专利发明点设计和专利文档起草。请根据解决的问题、解决方案及权利要求，\n",
    "扩充权利要求部分的内容。扩充的方法是，先设计一个具体的应用场景，将权利要求转换为具体的实现步骤，并结合应用场景进行描述每一步的输入输出，以及中间的处理过程。\n",
    "若是不同权利要求对应的操作步骤是相同的，则只需要在第一次给出描述，后面的则省略。\n",
    "\n",
    "要解决的问题: {question}\n",
    "提供的解决方案: {solution}\n",
    "独立权利要求: {claims}\n",
    "\n",
    "请将权利要求扩展为具体的实现步骤，并给出相应的示例说明：'''\n",
    "\n",
    "prompt_explanation = PromptTemplate(input_variables=['question', 'solution', 'claims'], template=template_explanation)\n",
    "explanation_chain = LLMChain(llm=llm, prompt=prompt_explanation, output_key='explanation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54a9d925-38a6-4bf1-b788-e0f97a7c51b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[background_chain, claims_chain, explanation_chain],\n",
    "    input_variables=[\"question\", \"solution\"],\n",
    "    # Here we return multiple variables\n",
    "    output_variables=[\"background\", \"claims\", \"explanation\"],\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37944f04-7c2c-41c6-9181-5adb531f29bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = overall_chain({'question': question, 'solution': solution})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "770814b1-ccd8-4210-b6ee-34761328e198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本发明涉及技术领域为流程挖掘和任务挖掘，特别是涉及识别UI操作流程中相同和不同的操作。在用户UI操作流程中，有些操作可能看起来完全不同，但实际上属于同一个业务操作。这个问题对于流程挖掘和任务挖掘来说是非常重要的，因为只有准确识别每个业务操作，才能进行有效的流程挖掘和任务挖掘。然而，目前使用图片相似性或文字比较等方法无法有效地解决这个问题，因为文字内容变化难以检测，而内容相差很大的UI操作可能属于同一个业务操作，因此需要一种新的解决方案。\n",
      "\n",
      "本发明提供了一种使用CV算法识别窗口/应用的区域，同时提取关键标签来判断UI操作属于同一个业务操作的方法。具体来说，本发明使用canny算法识别窗口的边框，通过边框识别窗口的主要布局，同一个应用内只有有限的窗口，每个窗口的布局是很少变化的。同时，本发明还提取一两个关键标签，代表当前操作的内容，比如窗口标题栏中的文字。只要窗口区域相似，关键标签相同，就可以判断两个UI操作属于同一个业务操作。\n",
      "\n",
      "本发明的解决方案可以有效地解决识别UI操作流程中相同和不同的操作的问题。本发明的解决方案可以准确地识别每个业务操作，从而实现有效的流程挖掘和任务挖掘。同时，本发明的解决方案具有较高的实用性和广泛的应用前景，可以应用于各种UI操作流程识别和分析的场景中。\n"
     ]
    }
   ],
   "source": [
    "print(result['background'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dcd95ea-174a-4961-99a2-0396e5995018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 一种UI操作识别方法，包括以下步骤：\n",
      "a. 通过边框识别窗口的主要布局；\n",
      "b. 提取窗口中的所有文字；\n",
      "c. 提取关键位置的文字，比如窗口标题栏中的文字；\n",
      "d. 对比窗口区域分布和关键标签，判断两个UI操作是否属于同一个业务操作。\n",
      "\n",
      "2. 根据权利要求1所述的UI操作识别方法，实现的一种系统。\n",
      "\n",
      "3. 根据权利要求1所述的UI操作识别方法，实现的一种计算机程序产品。\n",
      "\n",
      "4. 根据权利要求1所述的UI操作识别方法，应用于业务流程还原的一种方法。\n",
      "\n",
      "5. 根据权利要求1所述的UI操作识别方法，应用于用户行为分析的一种方法。\n",
      "\n",
      "6. 根据权利要求1所述的UI操作识别方法，应用于UI自动化测试的一种方法。\n",
      "\n",
      "7. 根据权利要求1所述的UI操作识别方法，应用于UI界面优化的一种方法。\n"
     ]
    }
   ],
   "source": [
    "print(result['claims'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9192b087-a95e-4ac1-b8e7-738b2015b326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 一种UI操作识别方法，包括以下步骤：\n",
      "a. 通过边框识别窗口的主要布局；\n",
      "b. 使用OCR技术提取窗口中的所有文字；\n",
      "c. 根据关键词提取关键位置的文字，比如窗口标题栏中的文字；\n",
      "d. 对比窗口区域分布和关键标签，判断两个UI操作是否属于同一个业务操作。\n",
      "\n",
      "例如，对于一个报销单页面，通过边框识别出页面中的各个区域，如报销人信息、报销单信息、费用明细等。然后使用OCR技术提取出页面中所有的文字信息，包括姓名、部门、报销单号、费用明细等。再根据关键词提取出报销单号、报销人姓名等关键信息。最后，通过对比不同报销单页面中的区域分布和关键标签，判断它们是否属于同一个业务操作。\n",
      "\n",
      "2. 根据权利要求1所述的UI操作识别方法，实现的一种系统。\n",
      "该系统包括：边框识别模块、OCR文字提取模块、关键词提取模块和UI操作判断模块。\n",
      "\n",
      "例如，该系统可以应用于公司的财务管理系统，通过对财务系统中的各个页面进行识别和判断，帮助公司实现财务流程的自动化管理。\n",
      "\n",
      "3. 根据权利要求1所述的UI操作识别方法，实现的一种计算机程序产品。\n",
      "该计算机程序产品包括：边框识别程序、OCR文字提取程序、关键词提取程序和UI操作判断程序。\n",
      "\n",
      "例如，该计算机程序产品可以应用于各种企业管理系统中，帮助企业实现自动化流程管理和数据分析。\n",
      "\n",
      "4. 根据权利要求1所述的UI操作识别方法，应用于业务流程还原的一种方法。\n",
      "该方法包括以下步骤：\n",
      "a. 识别不同业务操作的UI页面；\n",
      "b. 提取页面中的关键信息；\n",
      "c. 判断不同页面是否属于同一个业务操作；\n",
      "d. 还原业务流程中的UI操作流程。\n",
      "\n",
      "例如，该方法可以应用于银行的贷款审批流程中，通过识别不同的审批页面，提取页面中的关键信息，判断不同页面是否属于同一个贷款审批流程，最终还原出贷款审批的UI操作流程。\n",
      "\n",
      "5. 根据权利要求1所述的UI操作识别方法，应用于用户行为分析的一种方法。\n",
      "该方法包括以下步骤：\n",
      "a. 识别用户在系统中的UI操作流程；\n",
      "b. 统计用户的操作行为数据；\n",
      "c. 分析用户的操作行为数据，找出用户的行为模式和偏好；\n",
      "d. 根据用户的行为模式和偏好，优化系统的UI设计。\n",
      "\n",
      "例如，该方法可以应用于电商平台中，通过识别用户在平台中的UI操作流程，统计用户的操作行为数据，分析用户的行为模式和偏好，从而优化平台的UI设计，提高用户的购物体验。\n",
      "\n",
      "6. 根据权利要求1所述的UI操作识别方法，应用于UI自动化测试的一种方法。\n",
      "该方法包括以下步骤：\n",
      "a. 识别不同的UI操作流程；\n",
      "b. 设计测试用例，模拟用户的UI操作流程；\n",
      "c. 执行测试用例，检测系统是否正常运行；\n",
      "d. 分析测试结果，找出系统中的缺陷和问题。\n",
      "\n",
      "例如，该方法可以应用于软件开发过程中，通过识别不同的UI操作流程，设计测试用例，模拟用户的UI操作流程，执行测试用例，检测系统是否正常运行，从而找出系统中的缺陷和问题，提高软件的质量和稳定性。\n",
      "\n",
      "7. 根据权利要求1所述的UI操作识别方法，应用于UI界面优化的一种方法。\n",
      "该方法包括以下步骤：\n",
      "a. 识别不同的UI操作流程；\n",
      "b. 分析用户的操作行为数据，找出用户的行为模式和偏好；\n",
      "c. 根据用户的行为模式和偏好，优化系统的UI设计；\n",
      "d. 测试优化后的UI界面，检测系统是否正常运行。\n",
      "\n",
      "例如，该方法可以应用于游戏开发过程中，通过识别不同的UI操作流程，分析用户的操作行为数据，找出用户的行为模式和偏好，根据用户的行为模式和偏好，优化游戏的UI设计，最终测试优化后的UI界面，检测游戏是否正常运行。\n"
     ]
    }
   ],
   "source": [
    "print(result['explanation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d28050a-0d86-4dea-846d-8746be5c25db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('patent-output2.txt', 'w') as f:\n",
    "    f.write('background: ' + result['background'])\n",
    "    f.write('\\n\\nclaims: ' + result['claims'])\n",
    "    f.write('\\n\\nexplanation: ' + result['explanation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c78b3ad-1c25-4482-8960-e2a8f7a5dcb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
