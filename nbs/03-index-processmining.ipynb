{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "{}\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa1c4788-841f-4492-a630-7f5bed7e32c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "import langchain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from InstructorEmbedding import INSTRUCTOR\n",
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "import tiktoken\n",
    "from llama_index import SimpleDirectoryReader, GPTVectorStoreIndex\n",
    "from llama_index import LangchainEmbedding, ServiceContext\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "from llama_index.langchain_helpers.text_splitter import TokenTextSplitter\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ee258df-9b0f-4cd5-aced-e29840a4cb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "docs_dir = Path('/home/jinzy/work/automation/ask_gpt/documents')\n",
    "text_splitter=TokenTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\", \n",
    "                                                      model_kwargs={\"device\": \"cuda\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ef393c1-292a-4176-969a-f248a3bd449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "#filename = '/home/jinzy/work/automation/ask_gpt/documents/process-mining-0529/process-discovery-algorithms/Leemans_thesis_Hierarchical Process Mining.pdf'\n",
    "\n",
    "def find_unprocessable_pdfs(directory):\n",
    "    unprocessable_pdfs = []\n",
    "\n",
    "    # Walk through the directory tree\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            # If the file is a PDF\n",
    "            if file.endswith('.pdf') or file.endswith('.PDF'):\n",
    "                pdf_path = os.path.join(root, file)\n",
    "                \n",
    "                # Attempt to open the file with PyPDF2\n",
    "                try:\n",
    "                    with open(pdf_path, 'rb') as f:\n",
    "                        PyPDF2.PdfReader(f)\n",
    "                except:\n",
    "                    print(pdf_path)\n",
    "                    # If an error is raised, add it to the list of unprocessable files\n",
    "                    unprocessable_pdfs.append(pdf_path)\n",
    "\n",
    "    return unprocessable_pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ea8020a-b4ab-48a6-ab35-2172be9a64f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_unprocessable_pdfs(docs_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41cd0281-20f5-4bff-81ad-d73b6a360e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiple definitions in dictionary at byte 0x1e96c6 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x1e9f9a for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x1e851d for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x1e925b for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x1e9b2f for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x1ea31a for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x1ebc64 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x1eaad5 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x1ec62a for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x1e7c4b for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x1ed4d7 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x1ecff3 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x1eaf10 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x1e8986 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x1e80b3 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x1eb34c for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x1ecb0d for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x1e8df0 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x1ed9bb for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x1ea697 for key /ToUnicode\n",
      "Multiple definitions in dictionary at byte 0x1ec147 for key /ToUnicode\n",
      "/home/jinzy/.conda/envs/gpt/lib/python3.9/site-packages/PyPDF2/_cmap.py:142: PdfReadWarning: Advanced encoding /GBK-EUC-H not implemented yet\n",
      "  warnings.warn(\n",
      "/home/jinzy/.conda/envs/gpt/lib/python3.9/site-packages/PyPDF2/_cmap.py:142: PdfReadWarning: Advanced encoding /UniGB-UTF16-H not implemented yet\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n"
     ]
    }
   ],
   "source": [
    "# Embed and store the texts\n",
    "# Supplying a persist_directory will store the embeddings on disk\n",
    "documents = SimpleDirectoryReader(docs_dir, recursive=True, required_exts=['.txt', '.pdf'], errors='ignore').load_data()\n",
    "print(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f16a9427-f388-4731-8e0a-5a90a37da48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = SimpleNodeParser(text_splitter=text_splitter)\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    embed_model=LangchainEmbedding(instructor_embeddings), node_parser=node_parser\n",
    ")\n",
    "index = GPTVectorStoreIndex.from_documents(documents, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6b45478-03da-4dc4-b020-5c47436d3819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n任务挖掘是一种机器学习技术，它可以从大量的数据中提取有用的信息，以发现有价值的模式和规律。它可以帮助企业更好地理解客户的行为，并为企业提供有用的洞察，以改善客户体验和提高企业的效率。'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "r = query_engine.query('请解释一下什么是任务挖掘?')\n",
    "r.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3281c88-28ad-4c0f-bcbe-a042c0a678ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=Node(text='©', doc_id='42403477-d039-4535-adb7-8012c28cc2eb', embedding=None, doc_hash='cadd241f8828aab05b32b0dd8eba71ecf51cc548de4d7cc1c87218d09995cb56', extra_info=None, node_info={'start': 44165, 'end': 44166}, relationships={<DocumentRelationship.SOURCE: '1'>: '82e4ed06-4cbe-43f8-b438-bffcdb55946c', <DocumentRelationship.PREVIOUS: '2'>: 'ac92a0f3-c5da-4c50-aa2e-767a9785fe33', <DocumentRelationship.NEXT: '3'>: '06497e14-fca1-4fc4-8dad-9ef75c9f00e5'}), score=0.8781919393015661),\n",
       " NodeWithScore(node=Node(text='©', doc_id='06497e14-fca1-4fc4-8dad-9ef75c9f00e5', embedding=None, doc_hash='cadd241f8828aab05b32b0dd8eba71ecf51cc548de4d7cc1c87218d09995cb56', extra_info=None, node_info={'start': 44166, 'end': 44167}, relationships={<DocumentRelationship.SOURCE: '1'>: '82e4ed06-4cbe-43f8-b438-bffcdb55946c', <DocumentRelationship.PREVIOUS: '2'>: '42403477-d039-4535-adb7-8012c28cc2eb', <DocumentRelationship.NEXT: '3'>: 'ae946c3b-eb48-494d-9f43-76d5b5ea1b35'}), score=0.8781919393015661)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.source_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4d87747-c69c-46ef-87f3-82bddb27c29b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'42403477-d039-4535-adb7-8012c28cc2eb': None,\n",
       " '06497e14-fca1-4fc4-8dad-9ef75c9f00e5': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.extra_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "894e778f-e222-47cb-824b-d2f65db9a164",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'rpmv1'\n",
    "index.storage_context.persist(persist_dir=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ab6be1b-964f-4da0-925e-aca86c864c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n流程挖掘是一种数据挖掘技术，它可以从历史事件日志中提取有用的信息，以发现业务流程的模式和规律。它可以帮助企业更好地理解业务流程，并有助于优化业务流程，以提高企业的效率和效果。'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = query_engine.query('请解释一下什么是流程挖掘?')\n",
    "r.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9b1be0-3c40-40fe-ab6e-e44071c1a4d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
